{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b63624a0-ef03-44ee-882a-fe58c3b33c2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/yefeng/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from  sklearn.decomposition import NMF\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.patheffects as PathEffects\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from textblob import TextBlob\n",
    "from sklearn.preprocessing import normalize\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8aa459ea-e534-472f-b427-58f1635ed7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/OnTheSnow_SkiAreaReviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4364e8d0-6c23-41a4-873e-dfec126ac6a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18262 entries, 0 to 18261\n",
      "Data columns (total 6 columns):\n",
      " #   Column                         Non-Null Count  Dtype \n",
      "---  ------                         --------------  ----- \n",
      " 0   State                          18262 non-null  object\n",
      " 1   Ski Area                       18262 non-null  object\n",
      " 2   Reviewer Name                  18153 non-null  object\n",
      " 3   Review Date                    18262 non-null  object\n",
      " 4   Review Star Rating (out of 5)  18262 non-null  int64 \n",
      " 5   Review Text                    18250 non-null  object\n",
      "dtypes: int64(1), object(5)\n",
      "memory usage: 856.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "32631d05-54f1-4542-b0f0-305df0d9fadb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "291"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['Ski Area'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72e577eb-7371-457d-bcc1-3f52da5623c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentence'] = [sent_tokenize(str(rev)) for rev in df['Review Text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "36458094-8bed-4f9a-ad3c-9a183f023d34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [I'm glad our family experienced Squaw but I w...\n",
       "1        [I went skiing today 5/22, granite chief was a...\n",
       "2        [We had a horrible experience on our family sk...\n",
       "3        [This is the first year I ski Squaw., I've bee...\n",
       "4        [Both Squaw and Alpine have incredible terrain...\n",
       "                               ...                        \n",
       "18257    [Looks like they only made snow on one trail.,...\n",
       "18258    [Looks cute from highway........ but not enoug...\n",
       "18259    [Place has incredible potential., Could be bes...\n",
       "18260    [Great exposure from interstate......... but l...\n",
       "18261    [My dad and I visited on a whim on our way bac...\n",
       "Name: sentence, Length: 18262, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "39cd5770-8109-40e8-8829-dd12e3569ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rev_id'] = [i for i in range(len(df))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23638842-6e00-454a-b491-ecf0af007987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a daataframe with a sentence per row\n",
    "\n",
    "\n",
    "rev_list = df['sentence'].tolist()\n",
    "rev_id = df['rev_id'].tolist()\n",
    "\n",
    "# create a list of all sentences and all review IDs of the same length\n",
    "sentence_list = []\n",
    "review_id = []\n",
    "for i, rec in enumerate(rev_list):\n",
    "    for sent in rec:\n",
    "        sentence_list.append(sent)\n",
    "        review_id.append(rev_id[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "312b5b4a-3241-4d88-99a1-9b336dbb6de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_dict = {}\n",
    "sent_dict['rev_id'] = review_id\n",
    "sent_dict['sentence'] = sentence_list\n",
    "\n",
    "df_sent = pd.DataFrame.from_dict(sent_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "490b8ab8-32f0-4d6b-afd8-cf030dabea3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatizer(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    tagged = nltk.pos_tag(tokens)\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lem_words = []\n",
    "    for tagged_word in tagged:\n",
    "        word = tagged_word[0].lower()\n",
    "        if tagged_word[1].startswith('VB'):\n",
    "            word_tag = 'v'\n",
    "        elif tagged_word[1].startswith('JJ'):\n",
    "            word_tag = 'a'\n",
    "        elif tagged_word[1].startswith('RB'):\n",
    "            word_tag = 'r'\n",
    "        else:\n",
    "            word_tag = 'n'\n",
    "                 \n",
    "        lem_words.append(lemmatizer.lemmatize(word,pos=word_tag))\n",
    "    return(lem_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f25b05d1-88ac-4ca4-8493-34a988ff9636",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sent['lem_sent_token'] = [lemmatizer(str(rev)) for rev in df_sent['sentence']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0ca6ae1f-2387-419f-831e-6e3924968c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sent['lem_sent_text'] = [\" \".join(lems) for lems in df_sent['lem_sent_token']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "919878ca-07f1-45da-8ed0-feb09bee04a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rev_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>lem_sent_token</th>\n",
       "      <th>lem_sent_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>I'm glad our family experienced Squaw but I wo...</td>\n",
       "      <td>[i, 'm, glad, our, family, experience, squaw, ...</td>\n",
       "      <td>i 'm glad our family experience squaw but i wo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Here is a list of cons in detail: \\n1.</td>\n",
       "      <td>[here, be, a, list, of, con, in, detail, :, 1, .]</td>\n",
       "      <td>here be a list of con in detail : 1 .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>The staff were moody which is odd for an expen...</td>\n",
       "      <td>[the, staff, be, moody, which, be, odd, for, a...</td>\n",
       "      <td>the staff be moody which be odd for an expensi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2.</td>\n",
       "      <td>[2, .]</td>\n",
       "      <td>2 .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>The on hill ski staff had the worst ego's.</td>\n",
       "      <td>[the, on, hill, ski, staff, have, the, bad, eg...</td>\n",
       "      <td>the on hill ski staff have the bad ego 's .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rev_id                                           sentence  \\\n",
       "0       0  I'm glad our family experienced Squaw but I wo...   \n",
       "1       0             Here is a list of cons in detail: \\n1.   \n",
       "2       0  The staff were moody which is odd for an expen...   \n",
       "3       0                                                 2.   \n",
       "4       0         The on hill ski staff had the worst ego's.   \n",
       "\n",
       "                                      lem_sent_token  \\\n",
       "0  [i, 'm, glad, our, family, experience, squaw, ...   \n",
       "1  [here, be, a, list, of, con, in, detail, :, 1, .]   \n",
       "2  [the, staff, be, moody, which, be, odd, for, a...   \n",
       "3                                             [2, .]   \n",
       "4  [the, on, hill, ski, staff, have, the, bad, eg...   \n",
       "\n",
       "                                       lem_sent_text  \n",
       "0  i 'm glad our family experience squaw but i wo...  \n",
       "1              here be a list of con in detail : 1 .  \n",
       "2  the staff be moody which be odd for an expensi...  \n",
       "3                                                2 .  \n",
       "4        the on hill ski staff have the bad ego 's .  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sent.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f6d90a62-a781-4db2-8364-e35408c56fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/filtered_sent_lemm.pkl', 'wb') as picklefile:\n",
    "    pickle.dump(df_sent, picklefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f17ca0-7f5a-45a0-b2ef-67277eafe0ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
